{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0687ea5f",
   "metadata": {},
   "source": [
    "# One-Class Soil Classification: Training Phase (CLIP Prototype Method)\n",
    "\n",
    "**Author:** Siddhant Bhardwaj\n",
    "**Team Name:** Siddhant Bhardwaj\n",
    "**Team Members:** Siddhant Bhardwaj, Sivadhanushya \n",
    "**Leaderboard Rank:** 36 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Author: Siddhant Bhardwaj\n",
    "Team Name: Siddhant Bhardwaj\n",
    "Team Members: Siddhant, Sivadhanushya\n",
    "Leaderboard Rank: 36\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Jupyter Notebook Cell 2 (Code)\n",
    "# --- 1. Setup and Configuration ---\n",
    "print(\"--- [1] Initializing: Importing Libraries and Setting Configuration ---\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Configuration (should match your other files)\n",
    "BASE_PATH = '/kaggle/input/soil-classification-part-2/soil_competition-2025'\n",
    "TRAIN_LABELS_PATH = f'{BASE_PATH}/train_labels.csv'\n",
    "TRAIN_IMG_PATH = f'{BASE_PATH}/train'\n",
    "CLIP_MODEL_NAME = \"openai/clip-vit-base-patch16\"\n",
    "SIMILARITY_THRESHOLD_PERCENTILE = 5.5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME_FOR_FILE = CLIP_MODEL_NAME.split('/')[-1].replace(\"-\", \"_\")\n",
    "\n",
    "# Output files from this \"training\" phase\n",
    "PROTOTYPE_FILE = f'soil_prototype_{MODEL_NAME_FOR_FILE}.npy'\n",
    "THRESHOLD_FILE = f'similarity_threshold_{MODEL_NAME_FOR_FILE}_p{SIMILARITY_THRESHOLD_PERCENTILE:.1f}.txt'\n",
    "TRAINING_SIMILARITIES_PLOT_FILE = f'training_similarities_dist_{MODEL_NAME_FOR_FILE}_p{SIMILARITY_THRESHOLD_PERCENTILE:.1f}.png'\n",
    "\n",
    "print(f\"Device: {DEVICE}, CLIP Model: {CLIP_MODEL_NAME}, Percentile: {SIMILARITY_THRESHOLD_PERCENTILE}%\")\n",
    "print(f\"Will save prototype to: {PROTOTYPE_FILE}\")\n",
    "print(f\"Will save threshold to: {THRESHOLD_FILE}\")\n",
    "\n",
    "# In a Jupyter Notebook Cell 3 (Code)\n",
    "# --- 2. Load CLIP Model & Processor ---\n",
    "print(\"\\n--- [2] Loading CLIP Model ---\")\n",
    "try:\n",
    "    clip_model = CLIPModel.from_pretrained(CLIP_MODEL_NAME).to(DEVICE)\n",
    "    clip_processor = CLIPProcessor.from_pretrained(CLIP_MODEL_NAME)\n",
    "    clip_model.eval()\n",
    "    print(\"CLIP model and processor loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CLIP model: {e}\"); raise e\n",
    "\n",
    "# In a Jupyter Notebook Cell 4 (Code)\n",
    "# --- 3. Load Training Data & Display Samples ---\n",
    "print(\"\\n--- [3] Loading Training Data ---\")\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_LABELS_PATH)\n",
    "    train_image_ids_original = train_df['image_id'].tolist()\n",
    "    if not train_image_ids_original: raise ValueError(\"No training IDs.\")\n",
    "    print(f\"Loaded {len(train_image_ids_original)} training image IDs.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading training data: {e}\"); raise e\n",
    "\n",
    "# (Code to display sample training images - same as in the main script, for brevity I'll skip pasting it here again)\n",
    "# ... Ensure you include the sample image display code ...\n",
    "print(\"Displaying sample training images (refer to main script's plotting for full code)...\")\n",
    "# For actual notebook, copy the image display cell from the main script here.\n",
    "\n",
    "# In a Jupyter Notebook Cell 5 (Code)\n",
    "# --- 4. CLIP Embedding Function and Extraction for Training Data ---\n",
    "print(\"\\n--- [4] Extracting Training Image Embeddings ---\")\n",
    "# (Function definition for get_clip_image_embeddings - same as in the main script)\n",
    "def get_clip_image_embeddings(image_ids_list, img_directory, model, processor, device, model_name_desc):\n",
    "    embeddings_list = []\n",
    "    valid_ids_processed = []\n",
    "    model.eval()\n",
    "    for img_id in tqdm(image_ids_list, desc=f\"Extracting Embeddings ({model_name_desc})\"):\n",
    "        img_path = os.path.join(img_directory, img_id)\n",
    "        if not os.path.exists(img_path): continue\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            inputs = processor(text=None, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "            with torch.no_grad():\n",
    "                image_features = model.get_image_features(pixel_values=inputs.pixel_values)\n",
    "            embeddings_list.append(image_features.cpu().numpy().flatten())\n",
    "            valid_ids_processed.append(img_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error processing '{img_id}': {e}. Skipping.\")\n",
    "            continue\n",
    "    if not embeddings_list: return np.array([]), []\n",
    "    return np.array(embeddings_list), valid_ids_processed\n",
    "\n",
    "train_clip_embeddings, _ = get_clip_image_embeddings(\n",
    "    train_image_ids_original, TRAIN_IMG_PATH, clip_model, clip_processor, DEVICE, MODEL_NAME_FOR_FILE\n",
    ")\n",
    "if train_clip_embeddings.shape[0] == 0: \n",
    "    print(\"Error: No training embeddings extracted.\"); raise ValueError(\"No training embeddings\")\n",
    "print(f\"Training embeddings shape: {train_clip_embeddings.shape}\")\n",
    "\n",
    "# In a Jupyter Notebook Cell 6 (Code)\n",
    "# --- 5. Calculate Soil Prototype & Save ---\n",
    "print(\"\\n--- [5] Calculating and Saving Soil Prototype ---\")\n",
    "soil_prototype = np.mean(train_clip_embeddings, axis=0)\n",
    "np.save(PROTOTYPE_FILE, soil_prototype)\n",
    "print(f\"Soil prototype calculated. Shape: {soil_prototype.shape}. Saved to {PROTOTYPE_FILE}\")\n",
    "\n",
    "# In a Jupyter Notebook Cell 7 (Code)\n",
    "# --- 6. Determine & Save Similarity Threshold ---\n",
    "print(\"\\n--- [6] Determining and Saving Similarity Threshold ---\")\n",
    "similarities_to_prototype_train = cosine_similarity(\n",
    "    train_clip_embeddings, soil_prototype.reshape(1, -1)\n",
    ").flatten()\n",
    "\n",
    "similarity_threshold = np.percentile(similarities_to_prototype_train, SIMILARITY_THRESHOLD_PERCENTILE)\n",
    "with open(THRESHOLD_FILE, 'w') as f:\n",
    "    f.write(str(similarity_threshold))\n",
    "print(f\"Similarity Threshold ({SIMILARITY_THRESHOLD_PERCENTILE}th percentile): {similarity_threshold:.6f}. Saved to {THRESHOLD_FILE}\")\n",
    "\n",
    "# Plot and save distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(similarities_to_prototype_train, kde=True, bins=50, color=\"forestgreen\")\n",
    "plt.title(f'Training Similarities to {MODEL_NAME_FOR_FILE} Prototype (Pctl: {SIMILARITY_THRESHOLD_PERCENTILE}%)', fontsize=12)\n",
    "plt.xlabel('Cosine Similarity'); plt.ylabel('Frequency')\n",
    "plt.axvline(similarity_threshold, color='r', linestyle='dashed', label=f'Threshold: {similarity_threshold:.4f}')\n",
    "plt.legend(); plt.grid(True, linestyle='--', alpha=0.6);\n",
    "plt.savefig(TRAINING_SIMILARITIES_PLOT_FILE)\n",
    "plt.show()\n",
    "print(f\"Training similarities distribution plot saved to {TRAINING_SIMILARITIES_PLOT_FILE}\")\n",
    "print(\"--- 'Training' Phase Complete: Prototype and Threshold are ready. ---\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
